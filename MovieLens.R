library(tidyverse)
library(dslabs)
library(caret)
library(lubridate)
data("movielens")

#para mirar como tabla
movielens %>% as.tibble()

#usuarios unicos
movielens %>%
  summarize(n_users = n_distinct(userId),
            n_movies = n_distinct(movieId))

set.seed(755)
test_index <- createDataPartition(y = movielens$rating,
                                  times = 1, p = 0.2,
                                  list = FALSE)

train_set <- movielens[-test_index,]
test_set <- movielens[test_index,]

#se deben eliminar en el set de evaluaci√≥n las peliculas
#que no tienen evaluaci√≥n en el set de entrenamiento

test_set <- test_set %>%
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")

#RMSE
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}

#primer modelo de recomendaci√≥n
#promedio de todas las calificaciones de las peliculas
mu_hat <- mean(train_set$rating)
mu_hat

#se aplica a todas las calificaciones desconocidas el mu_hat
naive_rmse <- RMSE(test_set$rating,mu_hat)
naive_rmse

#ese resultado es muy inocente y se puede mejorar
#pero que se ponga el resultado en una tabla para comparar

rmse_results <- tibble(method = "Solo el promedio", RMSE = naive_rmse)

rmse_results
#PERO EL RESULTADO DEL PROMEDIO A√öN ES MEJOR QUE UN RESULTADO AL AZAR
#por ejemplo si se replica el 3 en cada una de las peliculas
#que tienen rating y luego se compara con lo efectivamente puesto

alazar <- rep(3, nrow(test_set))
RMSE(test_set$rating, alazar)

#?lm
#midiendo con modelo lineal para 
#ver por promedio simple las calificaciones
#de cada una de las pel√≠culas
#pero no es lo mejor con lm porque tarda mucho
#fit <- lm(rating ~ as.factor(movieId), data = movielens)

#se podr√≠a hacer con un promedio simple de cada una de las pel√≠culas
mu <- mean(train_set$rating)
mu
#si restamos el mu del ratig. querria
#decir que la calificaci√≥n m√°xima ser√≠a 1.5

movie_avgs <- train_set %>%
  group_by(movieId) %>%
  summarize(b_i = mean(rating  - mu))

qplot(b_i, data = movie_avgs, bins = 10, color = I("black"))

predicted_ratings <- mu + test_set %>%
  left_join(movie_avgs, by="movieId") %>%
  pull (b_i)

RMSE(predicted_ratings, test_set$rating)

#ya existe mejora a un promedio simple

#ver si hay alg√∫n efecto de usuario
#cu√°l es la calificaci√≥n promedio de aquellos usuarios
#que han calificado m√°s de 100 pel√≠culas

train_set %>%
  group_by(userId) %>%
  filter(n()>=100) %>%
  summarize(b_u = mean(rating)) %>%
  ggplot(aes(b_u)) +
  geom_histogram(bins = 30, color = "black")

#entonces lo que se tendr√≠a que hacer es 
#es una modelaci√≥n lineal lm 
#lm(rating ~ as.factor(movieId) + as.factor(userId))

#pero ser√≠a lento, entonces lo que se har√° es una aproximaci√≥n
#calculo de mu y rating de peli y estimando al usuario

user_avgs <- train_set %>%
  left_join(movie_avgs, by = "movieId") %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

#ahora construyendo los predictores y ver si mejora el RMSE
predicted_ratings <- test_set %>%
  left_join(movie_avgs, by="movieId") %>%
  left_join(user_avgs, by= "userId") %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

RMSE(predicted_ratings, test_set$rating)


#ME HE QUEDADO EN LA PAGINA 679
#EL APARTADO 33.8
#Q1. Compute the number of ratings for each movie and then plot it against the year the movie came out. Use the square root transformation on the counts.
#What year has the highest median number of ratings?

movielens %>% group_by(movieId) %>%
  summarize(n = n(), year = as.character(first(year))) %>%
  qplot(year, n, data = ., geom = "boxplot") +
  coord_trans(y = "sqrt") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

#2. Vemos que, en promedio, las pel√≠culas que salieron despu√©s de 1993 obtienen m√°s calificaciones. Tambi√©n vemos que con las pel√≠culas m√°s nuevas, a partir de 1993, el n√∫mero de
#calificaciones disminuye con el a√±o: entre m√°s reciente sea una pel√≠cula, menos tiempo han
#tenido los usuarios para calificarla.
#Entre las pel√≠culas que salieron en 1993 o m√°s tarde, ¬øcu√°les son las 25 pel√≠culas con m√°s
#calificaciones por a√±o? Adem√°s, indique la calificaci√≥n promedio.

movielens %>%
  filter(year >= 1993) %>%
  group_by(movieId) %>%
  summarize(n = n(), years = 2018 - first(year),
            title = title[1],
            rating = mean(rating)) %>%
  mutate(rate = n/years) %>%
  top_n(25, rate) %>%
  arrange(desc(rate))

#3. De la tabla construida en el ejemplo anterior, vemos que las pel√≠culas mejor calificadas
#tienden a tener calificaciones superiores al promedio. Esto no es sorprendente: m√°s personas
#ven pel√≠culas populares. Para confirmar esto, estratifique las pel√≠culas posteriores a 1993 por
#calificaciones por a√±o y calcule sus calificaciones promedio. Haga un gr√°fico de la calificaci√≥n
#promedio versus calificaciones por a√±o y muestre un estimador de la tendencia.

movielens %>%
  filter(year >= 1993) %>%
  group_by(movieId) %>%
  summarize(n = n(), years = 2017 - first(year),
            title = title[1],
            rating = mean(rating)) %>%
  mutate(rate = n/years) %>%
  ggplot(aes(rate, rating)) +
  geom_point() +
  geom_smooth()

#Q5. The movielens dataset also includes a time stamp. This variable represents the time and data in which the rating was provided. The units are seconds since January 1, 1970. Create a new column date with the date.

movielens <- mutate(movielens, date = as_datetime(timestamp))

head(movielens)

#6. Calcule la calificaci√≥n promedio de cada semana y calcule este promedio para cada d√≠a.
#Sugerencia: use la funci√≥n round_date antes de group_by.

movielens %>% mutate(date = round_date(date, unit = "week")) %>%
  group_by(date) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(date, rating)) +
  geom_point() +
  geom_smooth()

#7. El gr√°fico muestra alguna evidencia de un efecto temporero. Si definimos ùëëùë¢,ùëñ como el d√≠a
#que el usuario ùë¢ hizo su calificaci√≥n de la pel√≠cula ùëñ, ¬øcu√°l de los siguientes modelos es el
#m√°s apropiado?

#d. ùëåùë¢,ùëñ = ùúá + ùëèùëñ + ùëèùë¢ + ùëì(ùëëùë¢,ùëñ) + ùúÄùë¢,ùëñ, con ùëì una funci√≥n suave de ùëëùë¢,ùëñ.

#8 8. Los datos movielens tambi√©n tienen un columna genres. Esta columna incluye todos
#los g√©neros que aplican a la pel√≠cula. Algunas pel√≠culas pertenecen a varios g√©neros. Defina
#una categor√≠a como cualquier combinaci√≥n que aparezca en esta columna. Mantenga solo
#categor√≠as con m√°s de 1,000 calificaciones. Luego, calcule el promedio y error est√°ndar para
#cada categor√≠a. Grafique estos usando diagramas de barras de error.

movielens %>% group_by(genres) %>%
  summarize(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n())) %>%
  filter(n >= 1000) %>%
  mutate(genres = reorder(genres, avg)) %>%
  ggplot(aes(x = genres, y = avg, ymin = avg - 2*se, ymax = avg + 2*se)) +
  geom_point() +
  geom_errorbar() +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

#33.9 Regularizaci√≥n
#probemos con s√≥lo el b_i para seleccionar los errores de peliculas
test_set %>%
  left_join(movie_avgs, by= "movieId") %>%
  mutate(residual = rating - (mu + b_i)) %>%
  arrange(desc(abs(residual))) %>%
  slice(1:10) %>%
  pull (title)

test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  mutate(residual = rating - (mu + b_i)) %>%
  arrange(desc(abs(residual))) %>%  
  slice(1:10) %>% 
  pull(title)

movie_titles <- movielens %>% 
  select(movieId, title) %>%
  distinct()

#segun el primer estimador, las 10 mejores peliculas

movie_avgs %>% left_join(movie_titles, by="movieId") %>%
  arrange(desc(b_i)) %>% 
  slice(1:10)  %>% 
  pull(title)

#segun el primer estimador, las 10 peores peliculas

movie_avgs %>% left_join(movie_titles, by="movieId") %>%
  arrange(b_i) %>% 
  slice(1:10)  %>% 
  pull(title)

#todas desconocidas, ver la frecuencia de calificaci√≥n

train_set %>% count(movieId) %>%
  left_join(movie_avgs, by="movieId") %>%
  left_join(movie_titles, by= "movieId") %>%
  arrange(desc(b_i)) %>%
  slice(1:10) %>%
  pull(n)

train_set %>% count(movieId) %>%
  left_join(movie_avgs, by="movieId") %>%
  left_join(movie_titles, by= "movieId") %>%
  arrange(b_i) %>%
  slice(1:10) %>%
  pull(n)

#penalizando a las pelis que no tienen muchas valoraciones

lambda <- 3

mu <- mean(train_set$rating)

#regularizando los promedios de las peliculas
movie_reg_avgs <- train_set %>%
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda), n_i = n())

#comparaci√≥n de los promedios simples y los regularizados

tibble(original = movie_avgs$b_i,
       regularizado = movie_reg_avgs$b_i,
       n = movie_reg_avgs$n_i) %>%
  ggplot(aes(original, regularizado, size=sqrt(n))) +
  geom_point(shape=1, alpha=0.5)

#ahora veamos las 10 mejores peliculas
train_set %>%
  count(movieId) %>%
  left_join(movie_reg_avgs, by = "movieId") %>%
  left_join(movie_titles, by = "movieId") %>%
  arrange(desc(b_i)) %>%
  slice(1:10) %>%
  pull(title)

#las peores peliculas
train_set %>%
  count(movieId) %>%
  left_join(movie_reg_avgs, by = "movieId") %>%
  left_join(movie_titles, by = "movieId") %>%
  arrange(b_i) %>%
  slice(1:10) %>%
  pull(title)

#los resultados mejoraron?
predicted_ratings_con_penalizacion <- test_set %>%
  left_join(movie_reg_avgs, by="movieId") %>%
  mutate(pred = mu + b_i) %>%
  pull (pred)
RMSE(predicted_ratings_con_penalizacion, test_set$rating)

#pero como se podr√≠a elegir la cantidad para penalizar
#como podr√≠amos saber los valores de ajuste lambda
#validaci√≥n cruzada

lambdas <- seq(0,10,0.25)
mu <- mean(train_set$rating)
solo_la_suma <- train_set %>%
  group_by(movieId) %>%
  summarize(s = sum(rating - mu), n_i = n())

rmses <- sapply(lambdas, function(l){
  predicted_ratings <- test_set %>%
    left_join(solo_la_suma, by="movieId") %>%
    mutate(b_i = s/(n_i+1)) %>%
    mutate(pred = mu + b_i) %>%
    pull(pred)
  return(RMSE(predicted_ratings, test_set$rating))
})
rmses <- sapply(lambdas, function(l){
  predicted_ratings <- test_set %>%
    left_join(just_the_sum, by='movieId') %>%
    mutate(b_i = s/(n_i+l)) %>%
    mutate(pred = mu + b_i) %>%
    pull(pred)
  return(RMSE(predicted_ratings, test_set$rating))
})

just_the_sum <- train_set %>%
  group_by(movieId) %>%
  summarize(s = sum(rating - mu), n_i = n())
rmses <- sapply(lambdas, function(l){
  predicted_ratings <- test_set %>%
    left_join(just_the_sum, by='movieId') %>%
    mutate(b_i = s/(n_i+l)) %>%
    mutate(pred = mu + b_i) %>%
    pull(pred)
  return(RMSE(predicted_ratings, test_set$rating))
})
qplot(lambdas, rmses)
lambdas[which.min(rmses)]

#el anterior ejemplo solo es para fines ilustrativos. en realdiad se tendr√≠a que hacer con solo el set de entrenamiento

lambdas <- seq(0, 10, 0.25)
rmses <- sapply(lambdas, function(l){
  mu <- mean(train_set$rating)
  b_i <- train_set %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  b_u <- train_set %>%
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  predicted_ratings <-
    test_set %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)
  return(RMSE(predicted_ratings, test_set$rating))
})
qplot(lambdas, rmses)

lambda <- lambdas[which.min(rmses)]
lambda

#ME QUEDE EN 33.11 PAGINA 688